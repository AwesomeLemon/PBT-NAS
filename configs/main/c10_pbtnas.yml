logs_path: '/export/scratch1/home/aleksand/s2/PBT-NAS/logs' # path to the logs dir

out_name_template: "{dataset_name}_{algorithm}_pop{population_size}_GanHard" # name of the experiment,
#                                                                            values from the config will be substituted

seed: 31173
seed_offset: 0 # this will be added to the seed, use it if you ran an experiment with one seed separately, and now want to run more
processes_per_gpu: 2 # Ray parameter. Note that it doesn't enforce VRAM separation, it's on you to figure out how many networks can be trained on a GPU simultaneously
num_cpus: 2 # Ray parameter: CPU cores per process
n_seeds: 3 # how many times to repeat the experiment (with different seeds)

continue_auto: true # if a run has been interrupted, running with the same config and this option set to True will automatically continue it.

ssh_user: aleksand
ray_head_node: star04.scilens.private
if_shared_fs: false # if file system is shared, no need to use ssh/rsync
final_upload_node: star04.scilens.private # after a run has finished, it will be uploaded to this node

cleanup_final: true # if all the checkpoints except for the best one should be deleted

dataset_name: cifar10advnas
dataset_parameters:
  dataset_path: '/export/scratch1/home/aleksand/s2/data/cifar10'
  train_batch_size: 40
  n_workers: 4

model_class: AdvNas
model_parameters:
  gf_dim: 256
  n_cells: 3
  n_cells_discr: 4
  bottom_width: 4
  latent_dim: 120
  g_activation: 'relu'
  df_dim: 128
  d_activation: 'relu'
  d_spectral_norm: true
  d_type: 'advnas_my' # GanHard: discriminator
  task: generation
  gan_target_res: 32
  if_search_projections: true # GanHard: search parameters of projections
  generator_batch_size_multiplier: 2

if_search_arch: true
shrink_perturb: [0.4, 0.1]

replace_arch_percent: 0.25 # probability to replace each layer during mixing
percent_parents_for_mixing: 0.25 # tau
percent_old_population_survive: 0.75 # 1 - tau
soups: [['best', '']]

optimizer_name: MyAdamW # adapted to preserve parts of the optimizer state dict for which the shapes match
lr: 0.0002
wd: 0.0
if_gen_avg: true # use weight averaging in the generator

algorithm: PBTNAS
population_size: 24
n_children: 6
max_epochs: 300
epochs_step: 10